{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Project 2</h1></center>\n",
    "<center><h1>Classification Task</h1></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre-Process Data</h2>\n",
    "<center><h2> Import Libraries and Setups </h2></center></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,OneHotEncoder,MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Reading the dataset </h2></center></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel('IPEDS_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID number</th>\n",
       "      <th>Name</th>\n",
       "      <th>year</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Highest degree offered</th>\n",
       "      <th>County name</th>\n",
       "      <th>Longitude location of institution</th>\n",
       "      <th>Latitude location of institution</th>\n",
       "      <th>Religious affiliation</th>\n",
       "      <th>Offers Less than one year certificate</th>\n",
       "      <th>...</th>\n",
       "      <th>Percent of freshmen  receiving federal grant aid</th>\n",
       "      <th>Percent of freshmen receiving Pell grants</th>\n",
       "      <th>Percent of freshmen receiving other federal grant aid</th>\n",
       "      <th>Percent of freshmen receiving state/local grant aid</th>\n",
       "      <th>Percent of freshmen receiving institutional grant aid</th>\n",
       "      <th>Percent of freshmen receiving student loan aid</th>\n",
       "      <th>Percent of freshmen receiving federal student loans</th>\n",
       "      <th>Percent of freshmen receiving other loan aid</th>\n",
       "      <th>Endowment assets (year end) per FTE enrollment (GASB)</th>\n",
       "      <th>Endowment assets (year end) per FTE enrollment (FASB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>2013</td>\n",
       "      <td>35762</td>\n",
       "      <td>Doctor's degree - research/scholarship</td>\n",
       "      <td>Madison County</td>\n",
       "      <td>-86.568502</td>\n",
       "      <td>34.783368</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>2013</td>\n",
       "      <td>35294-0110</td>\n",
       "      <td>Doctor's degree - research/scholarship and pro...</td>\n",
       "      <td>Jefferson County</td>\n",
       "      <td>-86.809170</td>\n",
       "      <td>33.502230</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24136.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100690</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>2013</td>\n",
       "      <td>36117-3553</td>\n",
       "      <td>Doctor's degree - research/scholarship and pro...</td>\n",
       "      <td>Montgomery County</td>\n",
       "      <td>-86.174010</td>\n",
       "      <td>32.362609</td>\n",
       "      <td>Churches of Christ</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100706</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>2013</td>\n",
       "      <td>35899</td>\n",
       "      <td>Doctor's degree - research/scholarship and pro...</td>\n",
       "      <td>Madison County</td>\n",
       "      <td>-86.638420</td>\n",
       "      <td>34.722818</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11502.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100724</td>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>2013</td>\n",
       "      <td>36104-0271</td>\n",
       "      <td>Doctor's degree - research/scholarship and pro...</td>\n",
       "      <td>Montgomery County</td>\n",
       "      <td>-86.295677</td>\n",
       "      <td>32.364317</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13202.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100751</td>\n",
       "      <td>The University of Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>35487-0166</td>\n",
       "      <td>Doctor's degree - research/scholarship and pro...</td>\n",
       "      <td>Tuscaloosa County</td>\n",
       "      <td>-87.545766</td>\n",
       "      <td>33.214400</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19469.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100812</td>\n",
       "      <td>Athens State University</td>\n",
       "      <td>2013</td>\n",
       "      <td>35611</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Limestone County</td>\n",
       "      <td>-86.965140</td>\n",
       "      <td>34.805625</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>854.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100830</td>\n",
       "      <td>Auburn University at Montgomery</td>\n",
       "      <td>2013</td>\n",
       "      <td>36117-3596</td>\n",
       "      <td>Doctor's degree - research/scholarship</td>\n",
       "      <td>Montgomery County</td>\n",
       "      <td>-86.177351</td>\n",
       "      <td>32.369939</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10736.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100858</td>\n",
       "      <td>Auburn University</td>\n",
       "      <td>2013</td>\n",
       "      <td>36849</td>\n",
       "      <td>Doctor's degree - research/scholarship and pro...</td>\n",
       "      <td>Lee County</td>\n",
       "      <td>-85.492409</td>\n",
       "      <td>32.600201</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22092.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100937</td>\n",
       "      <td>Birmingham Southern College</td>\n",
       "      <td>2013</td>\n",
       "      <td>35254</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Jefferson County</td>\n",
       "      <td>-86.853636</td>\n",
       "      <td>33.515453</td>\n",
       "      <td>United Methodist</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101073</td>\n",
       "      <td>Concordia College Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>36701</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Dallas County</td>\n",
       "      <td>-87.023531</td>\n",
       "      <td>32.424430</td>\n",
       "      <td>Lutheran Church - Missouri Synod</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>101189</td>\n",
       "      <td>Faulkner University</td>\n",
       "      <td>2013</td>\n",
       "      <td>36109-3378</td>\n",
       "      <td>Doctor's degree -  professional practice</td>\n",
       "      <td>Montgomery County</td>\n",
       "      <td>-86.216410</td>\n",
       "      <td>32.384181</td>\n",
       "      <td>Churches of Christ</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5494.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>101435</td>\n",
       "      <td>Huntingdon College</td>\n",
       "      <td>2013</td>\n",
       "      <td>36106-2148</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Montgomery County</td>\n",
       "      <td>-86.285313</td>\n",
       "      <td>32.350939</td>\n",
       "      <td>United Methodist</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>101480</td>\n",
       "      <td>Jacksonville State University</td>\n",
       "      <td>2013</td>\n",
       "      <td>36265</td>\n",
       "      <td>Doctor's degree - research/scholarship</td>\n",
       "      <td>Calhoun County</td>\n",
       "      <td>-85.766644</td>\n",
       "      <td>33.822128</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>101541</td>\n",
       "      <td>Judson College</td>\n",
       "      <td>2013</td>\n",
       "      <td>36756</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Perry County</td>\n",
       "      <td>-87.316127</td>\n",
       "      <td>32.630526</td>\n",
       "      <td>Baptist</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>101587</td>\n",
       "      <td>University of West Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>35470</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Sumter County</td>\n",
       "      <td>-88.186077</td>\n",
       "      <td>32.592440</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>101675</td>\n",
       "      <td>Miles College</td>\n",
       "      <td>2013</td>\n",
       "      <td>35064-2621</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Jefferson County</td>\n",
       "      <td>-86.908605</td>\n",
       "      <td>33.481306</td>\n",
       "      <td>Christian Methodist Episcopal</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101693</td>\n",
       "      <td>University of Mobile</td>\n",
       "      <td>2013</td>\n",
       "      <td>36613-2842</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Mobile County</td>\n",
       "      <td>-88.128934</td>\n",
       "      <td>30.793247</td>\n",
       "      <td>Southern Baptist</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>101709</td>\n",
       "      <td>University of Montevallo</td>\n",
       "      <td>2013</td>\n",
       "      <td>35115-6000</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Shelby County</td>\n",
       "      <td>-86.865099</td>\n",
       "      <td>33.106250</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5870.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>101879</td>\n",
       "      <td>University of North Alabama</td>\n",
       "      <td>2013</td>\n",
       "      <td>35632-0001</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Lauderdale County</td>\n",
       "      <td>-87.680999</td>\n",
       "      <td>34.806580</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Implied no</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4290.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID number                                 Name  year    ZIP code  \\\n",
       "0      100654             Alabama A & M University  2013       35762   \n",
       "1      100663  University of Alabama at Birmingham  2013  35294-0110   \n",
       "2      100690                   Amridge University  2013  36117-3553   \n",
       "3      100706  University of Alabama in Huntsville  2013       35899   \n",
       "4      100724             Alabama State University  2013  36104-0271   \n",
       "5      100751            The University of Alabama  2013  35487-0166   \n",
       "6      100812              Athens State University  2013       35611   \n",
       "7      100830      Auburn University at Montgomery  2013  36117-3596   \n",
       "8      100858                    Auburn University  2013       36849   \n",
       "9      100937          Birmingham Southern College  2013       35254   \n",
       "10     101073            Concordia College Alabama  2013       36701   \n",
       "11     101189                  Faulkner University  2013  36109-3378   \n",
       "12     101435                   Huntingdon College  2013  36106-2148   \n",
       "13     101480        Jacksonville State University  2013       36265   \n",
       "14     101541                       Judson College  2013       36756   \n",
       "15     101587           University of West Alabama  2013       35470   \n",
       "16     101675                        Miles College  2013  35064-2621   \n",
       "17     101693                 University of Mobile  2013  36613-2842   \n",
       "18     101709             University of Montevallo  2013  35115-6000   \n",
       "19     101879          University of North Alabama  2013  35632-0001   \n",
       "\n",
       "                               Highest degree offered        County name  \\\n",
       "0              Doctor's degree - research/scholarship     Madison County   \n",
       "1   Doctor's degree - research/scholarship and pro...   Jefferson County   \n",
       "2   Doctor's degree - research/scholarship and pro...  Montgomery County   \n",
       "3   Doctor's degree - research/scholarship and pro...     Madison County   \n",
       "4   Doctor's degree - research/scholarship and pro...  Montgomery County   \n",
       "5   Doctor's degree - research/scholarship and pro...  Tuscaloosa County   \n",
       "6                                   Bachelor's degree   Limestone County   \n",
       "7              Doctor's degree - research/scholarship  Montgomery County   \n",
       "8   Doctor's degree - research/scholarship and pro...         Lee County   \n",
       "9                                   Bachelor's degree   Jefferson County   \n",
       "10                                  Bachelor's degree      Dallas County   \n",
       "11           Doctor's degree -  professional practice  Montgomery County   \n",
       "12                                  Bachelor's degree  Montgomery County   \n",
       "13             Doctor's degree - research/scholarship     Calhoun County   \n",
       "14                                  Bachelor's degree       Perry County   \n",
       "15                                    Master's degree      Sumter County   \n",
       "16                                  Bachelor's degree   Jefferson County   \n",
       "17                                    Master's degree      Mobile County   \n",
       "18                                    Master's degree      Shelby County   \n",
       "19                                    Master's degree  Lauderdale County   \n",
       "\n",
       "    Longitude location of institution  Latitude location of institution  \\\n",
       "0                          -86.568502                         34.783368   \n",
       "1                          -86.809170                         33.502230   \n",
       "2                          -86.174010                         32.362609   \n",
       "3                          -86.638420                         34.722818   \n",
       "4                          -86.295677                         32.364317   \n",
       "5                          -87.545766                         33.214400   \n",
       "6                          -86.965140                         34.805625   \n",
       "7                          -86.177351                         32.369939   \n",
       "8                          -85.492409                         32.600201   \n",
       "9                          -86.853636                         33.515453   \n",
       "10                         -87.023531                         32.424430   \n",
       "11                         -86.216410                         32.384181   \n",
       "12                         -86.285313                         32.350939   \n",
       "13                         -85.766644                         33.822128   \n",
       "14                         -87.316127                         32.630526   \n",
       "15                         -88.186077                         32.592440   \n",
       "16                         -86.908605                         33.481306   \n",
       "17                         -88.128934                         30.793247   \n",
       "18                         -86.865099                         33.106250   \n",
       "19                         -87.680999                         34.806580   \n",
       "\n",
       "               Religious affiliation Offers Less than one year certificate  \\\n",
       "0                     Not applicable                            Implied no   \n",
       "1                     Not applicable                            Implied no   \n",
       "2                 Churches of Christ                            Implied no   \n",
       "3                     Not applicable                                   Yes   \n",
       "4                     Not applicable                            Implied no   \n",
       "5                     Not applicable                            Implied no   \n",
       "6                     Not applicable                            Implied no   \n",
       "7                     Not applicable                            Implied no   \n",
       "8                     Not applicable                            Implied no   \n",
       "9                   United Methodist                            Implied no   \n",
       "10  Lutheran Church - Missouri Synod                            Implied no   \n",
       "11                Churches of Christ                            Implied no   \n",
       "12                  United Methodist                            Implied no   \n",
       "13                    Not applicable                            Implied no   \n",
       "14                           Baptist                            Implied no   \n",
       "15                    Not applicable                            Implied no   \n",
       "16     Christian Methodist Episcopal                            Implied no   \n",
       "17                  Southern Baptist                            Implied no   \n",
       "18                    Not applicable                            Implied no   \n",
       "19                    Not applicable                            Implied no   \n",
       "\n",
       "    ... Percent of freshmen  receiving federal grant aid  \\\n",
       "0   ...                                             81.0   \n",
       "1   ...                                             36.0   \n",
       "2   ...                                             90.0   \n",
       "3   ...                                             31.0   \n",
       "4   ...                                             76.0   \n",
       "5   ...                                             20.0   \n",
       "6   ...                                              NaN   \n",
       "7   ...                                             48.0   \n",
       "8   ...                                             13.0   \n",
       "9   ...                                             21.0   \n",
       "10  ...                                            100.0   \n",
       "11  ...                                             57.0   \n",
       "12  ...                                             48.0   \n",
       "13  ...                                             48.0   \n",
       "14  ...                                             82.0   \n",
       "15  ...                                             74.0   \n",
       "16  ...                                             88.0   \n",
       "17  ...                                             34.0   \n",
       "18  ...                                             38.0   \n",
       "19  ...                                             54.0   \n",
       "\n",
       "   Percent of freshmen receiving Pell grants  \\\n",
       "0                                       81.0   \n",
       "1                                       36.0   \n",
       "2                                       90.0   \n",
       "3                                       31.0   \n",
       "4                                       76.0   \n",
       "5                                       18.0   \n",
       "6                                        NaN   \n",
       "7                                       48.0   \n",
       "8                                       13.0   \n",
       "9                                       21.0   \n",
       "10                                      84.0   \n",
       "11                                      57.0   \n",
       "12                                      48.0   \n",
       "13                                      48.0   \n",
       "14                                      64.0   \n",
       "15                                      59.0   \n",
       "16                                      88.0   \n",
       "17                                      34.0   \n",
       "18                                      38.0   \n",
       "19                                      53.0   \n",
       "\n",
       "   Percent of freshmen receiving other federal grant aid  \\\n",
       "0                                                 7.0      \n",
       "1                                                10.0      \n",
       "2                                                 0.0      \n",
       "3                                                 4.0      \n",
       "4                                                13.0      \n",
       "5                                                 4.0      \n",
       "6                                                 NaN      \n",
       "7                                                 5.0      \n",
       "8                                                 3.0      \n",
       "9                                                 9.0      \n",
       "10                                               16.0      \n",
       "11                                               34.0      \n",
       "12                                               16.0      \n",
       "13                                               11.0      \n",
       "14                                               18.0      \n",
       "15                                               16.0      \n",
       "16                                               26.0      \n",
       "17                                                7.0      \n",
       "18                                                5.0      \n",
       "19                                               19.0      \n",
       "\n",
       "   Percent of freshmen receiving state/local grant aid  \\\n",
       "0                                                 1.0    \n",
       "1                                                 0.0    \n",
       "2                                                40.0    \n",
       "3                                                 1.0    \n",
       "4                                                11.0    \n",
       "5                                                 3.0    \n",
       "6                                                 NaN    \n",
       "7                                                 5.0    \n",
       "8                                                 1.0    \n",
       "9                                                26.0    \n",
       "10                                               83.0    \n",
       "11                                               64.0    \n",
       "12                                               53.0    \n",
       "13                                               21.0    \n",
       "14                                               84.0    \n",
       "15                                                2.0    \n",
       "16                                               10.0    \n",
       "17                                               44.0    \n",
       "18                                                1.0    \n",
       "19                                                2.0    \n",
       "\n",
       "   Percent of freshmen receiving institutional grant aid  \\\n",
       "0                                                32.0      \n",
       "1                                                60.0      \n",
       "2                                                90.0      \n",
       "3                                                63.0      \n",
       "4                                                34.0      \n",
       "5                                                50.0      \n",
       "6                                                 NaN      \n",
       "7                                                48.0      \n",
       "8                                                65.0      \n",
       "9                                                96.0      \n",
       "10                                               67.0      \n",
       "11                                               91.0      \n",
       "12                                               99.0      \n",
       "13                                               55.0      \n",
       "14                                              100.0      \n",
       "15                                               56.0      \n",
       "16                                               34.0      \n",
       "17                                               92.0      \n",
       "18                                               63.0      \n",
       "19                                               40.0      \n",
       "\n",
       "   Percent of freshmen receiving student loan aid  \\\n",
       "0                                            89.0   \n",
       "1                                            56.0   \n",
       "2                                           100.0   \n",
       "3                                            46.0   \n",
       "4                                            81.0   \n",
       "5                                            42.0   \n",
       "6                                             NaN   \n",
       "7                                            36.0   \n",
       "8                                            32.0   \n",
       "9                                            80.0   \n",
       "10                                          100.0   \n",
       "11                                           79.0   \n",
       "12                                           78.0   \n",
       "13                                           57.0   \n",
       "14                                           83.0   \n",
       "15                                           81.0   \n",
       "16                                           90.0   \n",
       "17                                           59.0   \n",
       "18                                           55.0   \n",
       "19                                           70.0   \n",
       "\n",
       "   Percent of freshmen receiving federal student loans  \\\n",
       "0                                                89.0    \n",
       "1                                                55.0    \n",
       "2                                               100.0    \n",
       "3                                                46.0    \n",
       "4                                                81.0    \n",
       "5                                                41.0    \n",
       "6                                                 NaN    \n",
       "7                                                36.0    \n",
       "8                                                31.0    \n",
       "9                                                80.0    \n",
       "10                                              100.0    \n",
       "11                                               79.0    \n",
       "12                                               77.0    \n",
       "13                                               56.0    \n",
       "14                                               83.0    \n",
       "15                                               74.0    \n",
       "16                                               90.0    \n",
       "17                                               58.0    \n",
       "18                                               55.0    \n",
       "19                                               70.0    \n",
       "\n",
       "   Percent of freshmen receiving other loan aid  \\\n",
       "0                                           1.0   \n",
       "1                                           5.0   \n",
       "2                                           0.0   \n",
       "3                                           3.0   \n",
       "4                                           0.0   \n",
       "5                                           8.0   \n",
       "6                                           NaN   \n",
       "7                                           0.0   \n",
       "8                                           3.0   \n",
       "9                                           7.0   \n",
       "10                                          0.0   \n",
       "11                                          3.0   \n",
       "12                                         10.0   \n",
       "13                                          2.0   \n",
       "14                                         12.0   \n",
       "15                                          8.0   \n",
       "16                                          2.0   \n",
       "17                                          4.0   \n",
       "18                                          3.0   \n",
       "19                                          2.0   \n",
       "\n",
       "   Endowment assets (year end) per FTE enrollment (GASB)  \\\n",
       "0                                                 NaN      \n",
       "1                                             24136.0      \n",
       "2                                                 NaN      \n",
       "3                                             11502.0      \n",
       "4                                             13202.0      \n",
       "5                                             19469.0      \n",
       "6                                               854.0      \n",
       "7                                             10736.0      \n",
       "8                                             22092.0      \n",
       "9                                                 NaN      \n",
       "10                                                NaN      \n",
       "11                                                NaN      \n",
       "12                                                NaN      \n",
       "13                                             1488.0      \n",
       "14                                                NaN      \n",
       "15                                               97.0      \n",
       "16                                                NaN      \n",
       "17                                                NaN      \n",
       "18                                             5870.0      \n",
       "19                                             4290.0      \n",
       "\n",
       "   Endowment assets (year end) per FTE enrollment (FASB)  \n",
       "0                                                 NaN     \n",
       "1                                                 NaN     \n",
       "2                                               302.0     \n",
       "3                                                 NaN     \n",
       "4                                                 NaN     \n",
       "5                                                 NaN     \n",
       "6                                                 NaN     \n",
       "7                                                 NaN     \n",
       "8                                                 NaN     \n",
       "9                                             37598.0     \n",
       "10                                                NaN     \n",
       "11                                             5494.0     \n",
       "12                                            41486.0     \n",
       "13                                                NaN     \n",
       "14                                            44004.0     \n",
       "15                                                NaN     \n",
       "16                                            10086.0     \n",
       "17                                            14086.0     \n",
       "18                                                NaN     \n",
       "19                                                NaN     \n",
       "\n",
       "[20 rows x 145 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID number                                                                              int64\n",
       "Name                                                                                  object\n",
       "year                                                                                   int64\n",
       "ZIP code                                                                              object\n",
       "Highest degree offered                                                                object\n",
       "County name                                                                           object\n",
       "Longitude location of institution                                                    float64\n",
       "Latitude location of institution                                                     float64\n",
       "Religious affiliation                                                                 object\n",
       "Offers Less than one year certificate                                                 object\n",
       "Offers One but less than two years certificate                                        object\n",
       "Offers Associate's degree                                                             object\n",
       "Offers Two but less than 4 years certificate                                          object\n",
       "Offers Bachelor's degree                                                              object\n",
       "Offers Postbaccalaureate certificate                                                  object\n",
       "Offers Master's degree                                                                object\n",
       "Offers Post-master's certificate                                                      object\n",
       "Offers Doctor's degree - research/scholarship                                         object\n",
       "Offers Doctor's degree - professional practice                                        object\n",
       "Offers Doctor's degree - other                                                        object\n",
       "Offers Other degree                                                                   object\n",
       "Applicants total                                                                     float64\n",
       "Admissions total                                                                     float64\n",
       "Enrolled total                                                                       float64\n",
       "Percent of freshmen submitting SAT scores                                            float64\n",
       "Percent of freshmen submitting ACT scores                                            float64\n",
       "SAT Critical Reading 25th percentile score                                           float64\n",
       "SAT Critical Reading 75th percentile score                                           float64\n",
       "SAT Math 25th percentile score                                                       float64\n",
       "SAT Math 75th percentile score                                                       float64\n",
       "                                                                                      ...   \n",
       "Percent of graduate enrollment that are Native Hawaiian or Other Pacific Islander    float64\n",
       "Percent of graduate enrollment that are White                                        float64\n",
       "Percent of graduate enrollment that are two or more races                            float64\n",
       "Percent of graduate enrollment that are Race/ethnicity unknown                       float64\n",
       "Percent of graduate enrollment that are Nonresident Alien                            float64\n",
       "Percent of graduate enrollment that are Asian/Native Hawaiian/Pacific Islander       float64\n",
       "Percent of graduate enrollment that are women                                        float64\n",
       "Number of first-time undergraduates - in-state                                       float64\n",
       "Percent of first-time undergraduates - in-state                                      float64\n",
       "Number of first-time undergraduates - out-of-state                                   float64\n",
       "Percent of first-time undergraduates - out-of-state                                  float64\n",
       "Number of first-time undergraduates - foreign countries                              float64\n",
       "Percent of first-time undergraduates - foreign countries                             float64\n",
       "Number of first-time undergraduates - residence unknown                              float64\n",
       "Percent of first-time undergraduates - residence unknown                             float64\n",
       "Graduation rate - Bachelor degree within 4 years, total                              float64\n",
       "Graduation rate - Bachelor degree within 5 years, total                              float64\n",
       "Graduation rate - Bachelor degree within 6 years, total                              float64\n",
       "Percent of freshmen receiving any financial aid                                      float64\n",
       "Percent of freshmen receiving federal, state, local or institutional grant aid       float64\n",
       "Percent of freshmen  receiving federal grant aid                                     float64\n",
       "Percent of freshmen receiving Pell grants                                            float64\n",
       "Percent of freshmen receiving other federal grant aid                                float64\n",
       "Percent of freshmen receiving state/local grant aid                                  float64\n",
       "Percent of freshmen receiving institutional grant aid                                float64\n",
       "Percent of freshmen receiving student loan aid                                       float64\n",
       "Percent of freshmen receiving federal student loans                                  float64\n",
       "Percent of freshmen receiving other loan aid                                         float64\n",
       "Endowment assets (year end) per FTE enrollment (GASB)                                float64\n",
       "Endowment assets (year end) per FTE enrollment (FASB)                                float64\n",
       "Length: 145, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pre-Process Data and dropping the columns</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['ID number','Name','year','ZIP code','County name','Longitude location of institution','Latitude location of institution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fiiling the missing values</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    if data[i].dtype=='object' and i.find('Offers')!=-1:\n",
    "        data[i]=data[i].fillna('Implied no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Religious affiliation']=data['Religious affiliation'].fillna('Not applicable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using Imputer with mean for missing values</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "  count=0\n",
    "  avg=0\n",
    "  if data[i].dtype=='float64':\n",
    "      avg = data[i].fillna(0).sum()/len(data[i])\n",
    "      data[i] = data[i].fillna(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using Label Encoder for object</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    if data[i].dtype=='object':\n",
    "        le=LabelEncoder()\n",
    "        data[i]=le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Defining Target variable</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[\"Offers Associate's degree\"].values\n",
    "X=data.drop(columns=\"Offers Associate's degree\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Highest degree offered</th>\n",
       "      <th>Religious affiliation</th>\n",
       "      <th>Offers Less than one year certificate</th>\n",
       "      <th>Offers One but less than two years certificate</th>\n",
       "      <th>Offers Associate's degree</th>\n",
       "      <th>Offers Two but less than 4 years certificate</th>\n",
       "      <th>Offers Bachelor's degree</th>\n",
       "      <th>Offers Postbaccalaureate certificate</th>\n",
       "      <th>Offers Master's degree</th>\n",
       "      <th>Offers Post-master's certificate</th>\n",
       "      <th>...</th>\n",
       "      <th>Percent of freshmen  receiving federal grant aid</th>\n",
       "      <th>Percent of freshmen receiving Pell grants</th>\n",
       "      <th>Percent of freshmen receiving other federal grant aid</th>\n",
       "      <th>Percent of freshmen receiving state/local grant aid</th>\n",
       "      <th>Percent of freshmen receiving institutional grant aid</th>\n",
       "      <th>Percent of freshmen receiving student loan aid</th>\n",
       "      <th>Percent of freshmen receiving federal student loans</th>\n",
       "      <th>Percent of freshmen receiving other loan aid</th>\n",
       "      <th>Endowment assets (year end) per FTE enrollment (GASB)</th>\n",
       "      <th>Endowment assets (year end) per FTE enrollment (FASB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3181.931551</td>\n",
       "      <td>40696.93807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24136.000000</td>\n",
       "      <td>40696.93807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3181.931551</td>\n",
       "      <td>302.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11502.000000</td>\n",
       "      <td>40696.93807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13202.000000</td>\n",
       "      <td>40696.93807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Highest degree offered  Religious affiliation  \\\n",
       "0                       3                     34   \n",
       "1                       4                     34   \n",
       "2                       4                     15   \n",
       "3                       4                     34   \n",
       "4                       4                     34   \n",
       "\n",
       "   Offers Less than one year certificate  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "2                                      0   \n",
       "3                                      1   \n",
       "4                                      0   \n",
       "\n",
       "   Offers One but less than two years certificate  Offers Associate's degree  \\\n",
       "0                                               0                          0   \n",
       "1                                               1                          0   \n",
       "2                                               0                          1   \n",
       "3                                               0                          0   \n",
       "4                                               0                          0   \n",
       "\n",
       "   Offers Two but less than 4 years certificate  Offers Bachelor's degree  \\\n",
       "0                                             0                         1   \n",
       "1                                             1                         1   \n",
       "2                                             0                         1   \n",
       "3                                             0                         1   \n",
       "4                                             0                         1   \n",
       "\n",
       "   Offers Postbaccalaureate certificate  Offers Master's degree  \\\n",
       "0                                     0                       1   \n",
       "1                                     1                       1   \n",
       "2                                     0                       1   \n",
       "3                                     1                       1   \n",
       "4                                     0                       1   \n",
       "\n",
       "   Offers Post-master's certificate  ...  \\\n",
       "0                                 0  ...   \n",
       "1                                 1  ...   \n",
       "2                                 0  ...   \n",
       "3                                 1  ...   \n",
       "4                                 1  ...   \n",
       "\n",
       "   Percent of freshmen  receiving federal grant aid  \\\n",
       "0                                              81.0   \n",
       "1                                              36.0   \n",
       "2                                              90.0   \n",
       "3                                              31.0   \n",
       "4                                              76.0   \n",
       "\n",
       "   Percent of freshmen receiving Pell grants  \\\n",
       "0                                       81.0   \n",
       "1                                       36.0   \n",
       "2                                       90.0   \n",
       "3                                       31.0   \n",
       "4                                       76.0   \n",
       "\n",
       "   Percent of freshmen receiving other federal grant aid  \\\n",
       "0                                                7.0       \n",
       "1                                               10.0       \n",
       "2                                                0.0       \n",
       "3                                                4.0       \n",
       "4                                               13.0       \n",
       "\n",
       "   Percent of freshmen receiving state/local grant aid  \\\n",
       "0                                                1.0     \n",
       "1                                                0.0     \n",
       "2                                               40.0     \n",
       "3                                                1.0     \n",
       "4                                               11.0     \n",
       "\n",
       "   Percent of freshmen receiving institutional grant aid  \\\n",
       "0                                               32.0       \n",
       "1                                               60.0       \n",
       "2                                               90.0       \n",
       "3                                               63.0       \n",
       "4                                               34.0       \n",
       "\n",
       "   Percent of freshmen receiving student loan aid  \\\n",
       "0                                            89.0   \n",
       "1                                            56.0   \n",
       "2                                           100.0   \n",
       "3                                            46.0   \n",
       "4                                            81.0   \n",
       "\n",
       "   Percent of freshmen receiving federal student loans  \\\n",
       "0                                               89.0     \n",
       "1                                               55.0     \n",
       "2                                              100.0     \n",
       "3                                               46.0     \n",
       "4                                               81.0     \n",
       "\n",
       "   Percent of freshmen receiving other loan aid  \\\n",
       "0                                           1.0   \n",
       "1                                           5.0   \n",
       "2                                           0.0   \n",
       "3                                           3.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   Endowment assets (year end) per FTE enrollment (GASB)  \\\n",
       "0                                        3181.931551       \n",
       "1                                       24136.000000       \n",
       "2                                        3181.931551       \n",
       "3                                       11502.000000       \n",
       "4                                       13202.000000       \n",
       "\n",
       "   Endowment assets (year end) per FTE enrollment (FASB)  \n",
       "0                                        40696.93807      \n",
       "1                                        40696.93807      \n",
       "2                                          302.00000      \n",
       "3                                        40696.93807      \n",
       "4                                        40696.93807      \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1465f740198>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\") \n",
    "sns.boxplot(x = 'Highest degree offered', y = 'Admissions total', data = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data in train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using Standard scaler for Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train) \n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard And Soft Voting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8229166666666666\n",
      "KNeighborsClassifier 0.7291666666666666\n",
      "SVC 0.75\n",
      "VotingClassifier 0.7864583333333334\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(X_train, y_train)\n",
    "knn_clf = KNeighborsClassifier(7)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "svm_clf = SVC(C = 10, probability = True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('svc', svm_clf)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8229166666666666\n",
      "KNeighborsClassifier 0.7291666666666666\n",
      "SVC 0.75\n",
      "VotingClassifier 0.7994791666666666\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(X_train, y_train)\n",
    "knn_clf = KNeighborsClassifier(7)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "svm_clf = SVC(C = 10, probability = True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('svc', svm_clf)], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GridSearch and CV for bagging and pasting both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6953125\n"
     ]
    }
   ],
   "source": [
    "model_bag_SVC=BaggingClassifier(base_estimator=SVC(kernel='poly',degree=2,C=100),n_estimators=25) \n",
    "model_bag_SVC.fit(X_train, y_train)\n",
    "y_pred = model_bag_SVC.predict(X_test)\n",
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Parameter precision\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 24}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.666 (+/-0.068) for {'n_estimators': 20}\n",
      "0.689 (+/-0.050) for {'n_estimators': 24}\n",
      "0.676 (+/-0.088) for {'n_estimators': 25}\n",
      "0.665 (+/-0.039) for {'n_estimators': 30}\n",
      "0.674 (+/-0.045) for {'n_estimators': 35}\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       219\n",
      "           1       0.66      0.61      0.63       165\n",
      "\n",
      "    accuracy                           0.70       384\n",
      "   macro avg       0.69      0.69      0.69       384\n",
      "weighted avg       0.69      0.70      0.69       384\n",
      "\n",
      "\n",
      "{'mean_fit_time': array([2.75203795, 3.30884333, 3.4780972 , 4.09292684, 4.86185102]), 'std_fit_time': array([0.03197244, 0.04300561, 0.18964812, 0.13712959, 0.07835304]), 'mean_score_time': array([0.49586763, 0.61063733, 0.61487722, 0.72180238, 0.85684447]), 'std_score_time': array([0.01013619, 0.04810044, 0.03373591, 0.01701684, 0.02483254]), 'param_n_estimators': masked_array(data=[20, 24, 25, 30, 35],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 20}, {'n_estimators': 24}, {'n_estimators': 25}, {'n_estimators': 30}, {'n_estimators': 35}], 'split0_test_score': array([0.61834928, 0.66825397, 0.61349206, 0.65      , 0.64562416]), 'split1_test_score': array([0.71414853, 0.72528016, 0.73255442, 0.69563492, 0.70970983]), 'split2_test_score': array([0.67870183, 0.71503705, 0.68772607, 0.66021029, 0.67380952]), 'split3_test_score': array([0.63730159, 0.66930192, 0.63814143, 0.64139531, 0.65555556]), 'split4_test_score': array([0.6790427 , 0.66961724, 0.70621333, 0.67848244, 0.68301857]), 'mean_test_score': array([0.66550878, 0.68949807, 0.67562546, 0.66514459, 0.67354353]), 'std_test_score': array([0.03389015, 0.02524694, 0.04379169, 0.01962291, 0.02236473]), 'rank_test_score': array([4, 1, 2, 5, 3])}\n",
      "MSE\n",
      "0.3046875\n",
      "ROC_AUC_Score\n",
      "0.6850560398505604\n",
      "Confusion Matrix\n",
      "[[166  53]\n",
      " [ 64 101]]\n",
      "Sensitivity: 0.6121212121212121\n",
      "Specificity: 0.7579908675799086\n",
      "Scoring Parameter recall\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 35}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.656 (+/-0.066) for {'n_estimators': 20}\n",
      "0.665 (+/-0.070) for {'n_estimators': 24}\n",
      "0.672 (+/-0.052) for {'n_estimators': 25}\n",
      "0.670 (+/-0.062) for {'n_estimators': 30}\n",
      "0.672 (+/-0.066) for {'n_estimators': 35}\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       219\n",
      "           1       0.65      0.62      0.63       165\n",
      "\n",
      "    accuracy                           0.69       384\n",
      "   macro avg       0.69      0.68      0.68       384\n",
      "weighted avg       0.69      0.69      0.69       384\n",
      "\n",
      "\n",
      "{'mean_fit_time': array([2.88464084, 3.26600962, 3.40040746, 4.23431692, 4.87004838]), 'std_fit_time': array([0.37643559, 0.09313241, 0.11942295, 0.13325083, 0.22256839]), 'mean_score_time': array([0.51960907, 0.59738545, 0.61276121, 0.7623632 , 0.87655435]), 'std_score_time': array([0.06226332, 0.01465019, 0.0133086 , 0.02333157, 0.03559015]), 'param_n_estimators': masked_array(data=[20, 24, 25, 30, 35],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 20}, {'n_estimators': 24}, {'n_estimators': 25}, {'n_estimators': 30}, {'n_estimators': 35}], 'split0_test_score': array([0.61116294, 0.61637127, 0.62608831, 0.63277363, 0.633551  ]), 'split1_test_score': array([0.69239739, 0.71843905, 0.69682836, 0.72364739, 0.7221704 ]), 'split2_test_score': array([0.68994652, 0.6707232 , 0.66975428, 0.68382296, 0.65804976]), 'split3_test_score': array([0.62657933, 0.64064801, 0.66739012, 0.65332145, 0.64956205]), 'split4_test_score': array([0.66180916, 0.67963724, 0.69789164, 0.65847609, 0.69789164]), 'mean_test_score': array([0.65637907, 0.66516375, 0.67159054, 0.6704083 , 0.67224497]), 'std_test_score': array([0.03282103, 0.03481487, 0.02615402, 0.03119314, 0.03275223]), 'rank_test_score': array([5, 4, 2, 3, 1])}\n",
      "MSE\n",
      "0.3072916666666667\n",
      "ROC_AUC_Score\n",
      "0.6835201328352012\n",
      "Confusion Matrix\n",
      "[[164  55]\n",
      " [ 63 102]]\n",
      "Sensitivity: 0.6181818181818182\n",
      "Specificity: 0.7488584474885844\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'n_estimators':[20,24,25,30,35]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "plot=defaultdict(int)\n",
    "\n",
    "for score in scores:\n",
    "    print('Scoring Parameter', score)\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    model_bag_SVC=BaggingClassifier(base_estimator=SVC(kernel='poly',degree=2,C=100))#,n_estimators=25)\n",
    "    model = GridSearchCV(model_bag_SVC, tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "   \n",
    "    yPred = model.predict(X_test)\n",
    "    print(classification_report(y_test, yPred))\n",
    "    # print(precision_score(y_test,yPred))\n",
    "    # dic=dict(classification_report(y_test,yPred))\n",
    "    # print(dic)\n",
    "    print()\n",
    "\n",
    "    print(model.cv_results_)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"MSE\")\n",
    "    print(mean_squared_error(y_test, yPred))\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print(\"ROC_AUC_Score\")\n",
    "    print(roc_auc_score(y_test, yPred))\n",
    "    \n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print('Confusion Matrix') \n",
    "    CM = confusion_matrix(y_test, yPred)\n",
    "    print (CM)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    print('Sensitivity:' ,sensitivity)\n",
    "    specificity = TN/(TN+FP)\n",
    "    print('Specificity:' ,specificity)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GridSearch and CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_bag_dt=BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=12),n_estimators=25)\n",
    "\n",
    "model_bag_dt.fit(X_train, y_train)\n",
    "y_pred = model_bag_dt.predict(X_test)\n",
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Parameter precision\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 20}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.922 (+/-0.023) for {'n_estimators': 20}\n",
      "0.917 (+/-0.014) for {'n_estimators': 24}\n",
      "0.915 (+/-0.032) for {'n_estimators': 25}\n",
      "0.915 (+/-0.032) for {'n_estimators': 30}\n",
      "0.915 (+/-0.027) for {'n_estimators': 35}\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       219\n",
      "           1       0.89      0.88      0.88       165\n",
      "\n",
      "    accuracy                           0.90       384\n",
      "   macro avg       0.90      0.90      0.90       384\n",
      "weighted avg       0.90      0.90      0.90       384\n",
      "\n",
      "\n",
      "MSE\n",
      "0.09895833333333333\n",
      "ROC_AUC_Score\n",
      "0.8982980489829806\n",
      "Confusion Matrix\n",
      "[[201  18]\n",
      " [ 20 145]]\n",
      "Sensitivity: 0.8787878787878788\n",
      "Specificity: 0.9178082191780822\n",
      "Scoring Parameter recall\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 25}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.913 (+/-0.037) for {'n_estimators': 20}\n",
      "0.915 (+/-0.032) for {'n_estimators': 24}\n",
      "0.919 (+/-0.026) for {'n_estimators': 25}\n",
      "0.917 (+/-0.032) for {'n_estimators': 30}\n",
      "0.918 (+/-0.026) for {'n_estimators': 35}\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       219\n",
      "           1       0.90      0.89      0.89       165\n",
      "\n",
      "    accuracy                           0.91       384\n",
      "   macro avg       0.91      0.91      0.91       384\n",
      "weighted avg       0.91      0.91      0.91       384\n",
      "\n",
      "\n",
      "MSE\n",
      "0.09114583333333333\n",
      "ROC_AUC_Score\n",
      "0.9066417600664176\n",
      "Confusion Matrix\n",
      "[[202  17]\n",
      " [ 18 147]]\n",
      "Sensitivity: 0.8909090909090909\n",
      "Specificity: 0.9223744292237442\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'n_estimators':[20,24,25,30,35]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print('Scoring Parameter', score)\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    model_bag_SVC=BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=12),bootstrap=False)#,n_estimators=25)\n",
    "    model = GridSearchCV(model_bag_SVC, tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "   \n",
    "    yPred = model.predict(X_test)\n",
    "    print(classification_report(y_test, yPred))\n",
    "    print()\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"MSE\")\n",
    "    print(mean_squared_error(y_test, yPred))\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print(\"ROC_AUC_Score\")\n",
    "    print(roc_auc_score(y_test, yPred))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print('Confusion Matrix') \n",
    "    CM = confusion_matrix(y_test, yPred)\n",
    "    print (CM)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    print('Sensitivity:' ,sensitivity)\n",
    "    specificity = TN/(TN+FP)\n",
    "    print('Specificity:' ,specificity)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Boost with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GridSearch and CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8984375\n"
     ]
    }
   ],
   "source": [
    "model_ada_DT=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=16),n_estimators=25,learning_rate=0.5,random_state=0)\n",
    "model_ada_DT.fit(X_train, y_train)\n",
    "y_pred = model_ada_DT.predict(X_test)\n",
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Parameter precision\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 20}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.919 (+/-0.052) for {'n_estimators': 20}\n",
      "0.918 (+/-0.049) for {'n_estimators': 24}\n",
      "0.918 (+/-0.049) for {'n_estimators': 25}\n",
      "0.916 (+/-0.045) for {'n_estimators': 30}\n",
      "0.917 (+/-0.047) for {'n_estimators': 35}\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       219\n",
      "           1       0.97      0.91      0.94       165\n",
      "\n",
      "    accuracy                           0.95       384\n",
      "   macro avg       0.95      0.95      0.95       384\n",
      "weighted avg       0.95      0.95      0.95       384\n",
      "\n",
      "\n",
      "MSE\n",
      "0.049479166666666664\n",
      "ROC_AUC_Score\n",
      "0.9454130344541304\n",
      "Confusion Matrix\n",
      "[[215   4]\n",
      " [ 15 150]]\n",
      "Sensitivity: 0.9090909090909091\n",
      "Specificity: 0.9817351598173516\n",
      "Scoring Parameter recall\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 20}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.915 (+/-0.055) for {'n_estimators': 20}\n",
      "0.914 (+/-0.054) for {'n_estimators': 24}\n",
      "0.914 (+/-0.054) for {'n_estimators': 25}\n",
      "0.913 (+/-0.050) for {'n_estimators': 30}\n",
      "0.914 (+/-0.052) for {'n_estimators': 35}\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       219\n",
      "           1       0.97      0.91      0.94       165\n",
      "\n",
      "    accuracy                           0.95       384\n",
      "   macro avg       0.95      0.95      0.95       384\n",
      "weighted avg       0.95      0.95      0.95       384\n",
      "\n",
      "\n",
      "MSE\n",
      "0.049479166666666664\n",
      "ROC_AUC_Score\n",
      "0.9454130344541304\n",
      "Confusion Matrix\n",
      "[[215   4]\n",
      " [ 15 150]]\n",
      "Sensitivity: 0.9090909090909091\n",
      "Specificity: 0.9817351598173516\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'n_estimators':[20,24,25,30,35]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print('Scoring Parameter', score)\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    model_bag_SVC=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=12),learning_rate=0.5,random_state=0)#,n_estimators=25)\n",
    "    model = GridSearchCV(model_bag_SVC, tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "   \n",
    "    yPred = model.predict(X_test)\n",
    "    print(classification_report(y_test, yPred))\n",
    "    print()\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"MSE\")\n",
    "    print(mean_squared_error(y_test, yPred))\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print(\"ROC_AUC_Score\")\n",
    "    print(roc_auc_score(y_test, yPred))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print('Confusion Matrix') \n",
    "    CM = confusion_matrix(y_test, yPred)\n",
    "    print (CM)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    print('Sensitivity:' ,sensitivity)\n",
    "    specificity = TN/(TN+FP)\n",
    "    print('Specificity:' ,specificity)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Boost with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6067708333333334\n"
     ]
    }
   ],
   "source": [
    "model_ada_SVC=AdaBoostClassifier(base_estimator=SVC(kernel='poly', degree=2,C=100),n_estimators=25,algorithm='SAMME')\n",
    "model_ada_SVC.fit(X_train, y_train)\n",
    "y_pred = model_ada_SVC.predict(X_test)\n",
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring Parameter precision\n",
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 25}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.675 (+/-0.055) for {'n_estimators': 20}\n",
      "0.671 (+/-0.054) for {'n_estimators': 24}\n",
      "0.676 (+/-0.060) for {'n_estimators': 25}\n",
      "0.675 (+/-0.057) for {'n_estimators': 30}\n",
      "0.675 (+/-0.060) for {'n_estimators': 35}\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       219\n",
      "           1       0.62      0.67      0.65       165\n",
      "\n",
      "    accuracy                           0.68       384\n",
      "   macro avg       0.68      0.68      0.68       384\n",
      "weighted avg       0.69      0.68      0.68       384\n",
      "\n",
      "\n",
      "MSE\n",
      "0.3177083333333333\n",
      "ROC_AUC_Score\n",
      "0.681112494811125\n",
      "Confusion Matrix\n",
      "[[151  68]\n",
      " [ 54 111]]\n",
      "Sensitivity: 0.6727272727272727\n",
      "Specificity: 0.6894977168949772\n",
      "Scoring Parameter recall\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 25}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.631 (+/-0.070) for {'n_estimators': 20}\n",
      "0.627 (+/-0.057) for {'n_estimators': 24}\n",
      "0.632 (+/-0.058) for {'n_estimators': 25}\n",
      "0.632 (+/-0.061) for {'n_estimators': 30}\n",
      "0.632 (+/-0.063) for {'n_estimators': 35}\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       219\n",
      "           1       0.62      0.67      0.65       165\n",
      "\n",
      "    accuracy                           0.68       384\n",
      "   macro avg       0.68      0.68      0.68       384\n",
      "weighted avg       0.69      0.68      0.68       384\n",
      "\n",
      "\n",
      "MSE\n",
      "0.3177083333333333\n",
      "ROC_AUC_Score\n",
      "0.681112494811125\n",
      "Confusion Matrix\n",
      "[[151  68]\n",
      " [ 54 111]]\n",
      "Sensitivity: 0.6727272727272727\n",
      "Specificity: 0.6894977168949772\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'n_estimators':[20,24,25,30,35]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print('Scoring Parameter', score)\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    model_bag_SVC=AdaBoostClassifier(base_estimator=SVC(kernel='poly', degree=2,C=100),algorithm=\"SAMME\",learning_rate=0.5,random_state=0)#,n_estimators=25)\n",
    "    model = GridSearchCV(model_bag_SVC, tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "   \n",
    "    yPred = model.predict(X_test)\n",
    "    print(classification_report(y_test, yPred))\n",
    "    print()\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"MSE\")\n",
    "    print(mean_squared_error(y_test, yPred))\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    print(\"ROC_AUC_Score\")\n",
    "    print(roc_auc_score(y_test, yPred))\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print('Confusion Matrix') \n",
    "    CM = confusion_matrix(y_test, yPred)\n",
    "    print (CM)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    print('Sensitivity:' ,sensitivity)\n",
    "    specificity = TN/(TN+FP)\n",
    "    print('Specificity:' ,specificity)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.982\n",
      "Accuracy on test set: 0.953\n",
      "Accuracy on training set: 0.956\n",
      "Accuracy on test set: 0.953\n",
      "Accuracy on training set: 0.955\n",
      "Accuracy on test set: 0.953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix shape (1150, 137)\n",
      "Test matrix shape (384, 137)\n"
     ]
    }
   ],
   "source": [
    "##### DEEP NEURAL NETWORKSfrom dklrstn\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# step 1: make the model - no hidden layer\n",
    "model = Sequential()\n",
    "#input layer: input)_dim: number of columns in X_train \n",
    "model.add(Dense(100, input_dim = X_train.shape[1] , activation = 'relu'))\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "#hidden layers\n",
    "#output\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: compile the model -> create the computational graph\n",
    "model.compile(loss='binary_crossentropy' , optimizer='adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1150 samples, validate on 384 samples\n",
      "WARNING:tensorflow:From c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1150/1150 [==============================] - 1s 686us/sample - loss: 0.6883 - acc: 0.5817 - val_loss: 0.6281 - val_acc: 0.7005\n",
      "Epoch 2/100\n",
      "1150/1150 [==============================] - 0s 44us/sample - loss: 0.6024 - acc: 0.6817 - val_loss: 0.5807 - val_acc: 0.7109\n",
      "Epoch 3/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.5470 - acc: 0.7339 - val_loss: 0.5340 - val_acc: 0.7526\n",
      "Epoch 4/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.4943 - acc: 0.7600 - val_loss: 0.5157 - val_acc: 0.7526\n",
      "Epoch 5/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.4545 - acc: 0.7887 - val_loss: 0.5004 - val_acc: 0.7422\n",
      "Epoch 6/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.4148 - acc: 0.8139 - val_loss: 0.4943 - val_acc: 0.7396\n",
      "Epoch 7/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.3835 - acc: 0.8339 - val_loss: 0.4925 - val_acc: 0.7474\n",
      "Epoch 8/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 0.3535 - acc: 0.8513 - val_loss: 0.4916 - val_acc: 0.7526\n",
      "Epoch 9/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.3271 - acc: 0.8643 - val_loss: 0.5042 - val_acc: 0.7526\n",
      "Epoch 10/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.3061 - acc: 0.8765 - val_loss: 0.5339 - val_acc: 0.7526\n",
      "Epoch 11/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.2793 - acc: 0.8922 - val_loss: 0.5182 - val_acc: 0.7552\n",
      "Epoch 12/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.2504 - acc: 0.9035 - val_loss: 0.5331 - val_acc: 0.7708\n",
      "Epoch 13/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.2283 - acc: 0.9183 - val_loss: 0.5543 - val_acc: 0.7448\n",
      "Epoch 14/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 0.2083 - acc: 0.9235 - val_loss: 0.5760 - val_acc: 0.7448\n",
      "Epoch 15/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.1874 - acc: 0.9365 - val_loss: 0.5762 - val_acc: 0.7500\n",
      "Epoch 16/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.1703 - acc: 0.9426 - val_loss: 0.5900 - val_acc: 0.7500\n",
      "Epoch 17/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.1519 - acc: 0.9635 - val_loss: 0.6372 - val_acc: 0.7422\n",
      "Epoch 18/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.1370 - acc: 0.9661 - val_loss: 0.6303 - val_acc: 0.7370\n",
      "Epoch 19/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.1185 - acc: 0.9670 - val_loss: 0.6415 - val_acc: 0.7422\n",
      "Epoch 20/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.1064 - acc: 0.9748 - val_loss: 0.6707 - val_acc: 0.7474\n",
      "Epoch 21/100\n",
      "1150/1150 [==============================] - 0s 44us/sample - loss: 0.0909 - acc: 0.9852 - val_loss: 0.6954 - val_acc: 0.7474\n",
      "Epoch 22/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0842 - acc: 0.9861 - val_loss: 0.7569 - val_acc: 0.7526\n",
      "Epoch 23/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0707 - acc: 0.9896 - val_loss: 0.7567 - val_acc: 0.7344\n",
      "Epoch 24/100\n",
      "1150/1150 [==============================] - 0s 70us/sample - loss: 0.0612 - acc: 0.9939 - val_loss: 0.7660 - val_acc: 0.7370\n",
      "Epoch 25/100\n",
      "1150/1150 [==============================] - 0s 43us/sample - loss: 0.0514 - acc: 0.9948 - val_loss: 0.8044 - val_acc: 0.7500\n",
      "Epoch 26/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.0439 - acc: 0.9974 - val_loss: 0.7971 - val_acc: 0.7500\n",
      "Epoch 27/100\n",
      "1150/1150 [==============================] - 0s 45us/sample - loss: 0.0388 - acc: 0.9974 - val_loss: 0.8378 - val_acc: 0.7396\n",
      "Epoch 28/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 0.0330 - acc: 0.9991 - val_loss: 0.8774 - val_acc: 0.7448\n",
      "Epoch 29/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.0284 - acc: 0.9991 - val_loss: 0.8981 - val_acc: 0.7500\n",
      "Epoch 30/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.0248 - acc: 0.9991 - val_loss: 0.9186 - val_acc: 0.7526\n",
      "Epoch 31/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0210 - acc: 0.9991 - val_loss: 0.9457 - val_acc: 0.7526\n",
      "Epoch 32/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.9596 - val_acc: 0.7448\n",
      "Epoch 33/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.7552\n",
      "Epoch 34/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.9727 - val_acc: 0.7526\n",
      "Epoch 35/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 1.0178 - val_acc: 0.7552\n",
      "Epoch 36/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 1.0202 - val_acc: 0.7526\n",
      "Epoch 37/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 1.0290 - val_acc: 0.7552\n",
      "Epoch 38/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 1.0617 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 1.0792 - val_acc: 0.7578\n",
      "Epoch 40/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 1.0766 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 1.1051 - val_acc: 0.7604\n",
      "Epoch 42/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 1.1071 - val_acc: 0.7578\n",
      "Epoch 43/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.1266 - val_acc: 0.7578\n",
      "Epoch 44/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 1.1453 - val_acc: 0.7578\n",
      "Epoch 45/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 1.1358 - val_acc: 0.7578\n",
      "Epoch 46/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 1.1811 - val_acc: 0.7578\n",
      "Epoch 47/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 1.1634 - val_acc: 0.7604\n",
      "Epoch 48/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 1.2009 - val_acc: 0.7552\n",
      "Epoch 49/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0032 - acc: 1.0000 - val_loss: 1.1995 - val_acc: 0.7578\n",
      "Epoch 50/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 1.2201 - val_acc: 0.7526\n",
      "Epoch 51/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.0028 - acc: 1.0000 - val_loss: 1.2234 - val_acc: 0.7552\n",
      "Epoch 52/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 1.2350 - val_acc: 0.7630\n",
      "Epoch 53/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0024 - acc: 1.0000 - val_loss: 1.2394 - val_acc: 0.7604\n",
      "Epoch 54/100\n",
      "1150/1150 [==============================] - 0s 38us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 1.2553 - val_acc: 0.7552\n",
      "Epoch 55/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 1.2582 - val_acc: 0.7552\n",
      "Epoch 56/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 1.2720 - val_acc: 0.7604\n",
      "Epoch 57/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 1.2756 - val_acc: 0.7578\n",
      "Epoch 58/100\n",
      "1150/1150 [==============================] - 0s 38us/sample - loss: 0.0019 - acc: 1.0000 - val_loss: 1.2896 - val_acc: 0.7552\n",
      "Epoch 59/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 1.2911 - val_acc: 0.7604\n",
      "Epoch 60/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 1.3030 - val_acc: 0.7604\n",
      "Epoch 61/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 1.3140 - val_acc: 0.7578\n",
      "Epoch 62/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 1.3192 - val_acc: 0.7552\n",
      "Epoch 63/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 1.3299 - val_acc: 0.7578\n",
      "Epoch 64/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 1.3352 - val_acc: 0.7578\n",
      "Epoch 65/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 1.3426 - val_acc: 0.7578\n",
      "Epoch 66/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 1.3488 - val_acc: 0.7578\n",
      "Epoch 67/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 0.0012 - acc: 1.0000 - val_loss: 1.3567 - val_acc: 0.7604\n",
      "Epoch 68/100\n",
      "1150/1150 [==============================] - 0s 43us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 1.3626 - val_acc: 0.7578\n",
      "Epoch 69/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 1.3707 - val_acc: 0.7578\n",
      "Epoch 70/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 1.3727 - val_acc: 0.7578\n",
      "Epoch 71/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 0.0010 - acc: 1.0000 - val_loss: 1.3802 - val_acc: 0.7578\n",
      "Epoch 72/100\n",
      "1150/1150 [==============================] - 0s 43us/sample - loss: 9.5692e-04 - acc: 1.0000 - val_loss: 1.3886 - val_acc: 0.7526\n",
      "Epoch 73/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 9.2522e-04 - acc: 1.0000 - val_loss: 1.3934 - val_acc: 0.7526\n",
      "Epoch 74/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 8.9248e-04 - acc: 1.0000 - val_loss: 1.4000 - val_acc: 0.7578\n",
      "Epoch 75/100\n",
      "1150/1150 [==============================] - 0s 37us/sample - loss: 8.5915e-04 - acc: 1.0000 - val_loss: 1.4081 - val_acc: 0.7552\n",
      "Epoch 76/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 8.2950e-04 - acc: 1.0000 - val_loss: 1.4070 - val_acc: 0.7552\n",
      "Epoch 77/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 8.0861e-04 - acc: 1.0000 - val_loss: 1.4182 - val_acc: 0.7526\n",
      "Epoch 78/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 7.7393e-04 - acc: 1.0000 - val_loss: 1.4188 - val_acc: 0.7578\n",
      "Epoch 79/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 7.4357e-04 - acc: 1.0000 - val_loss: 1.4295 - val_acc: 0.7578\n",
      "Epoch 80/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 7.1993e-04 - acc: 1.0000 - val_loss: 1.4326 - val_acc: 0.7578\n",
      "Epoch 81/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 6.9628e-04 - acc: 1.0000 - val_loss: 1.4394 - val_acc: 0.7552\n",
      "Epoch 82/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 6.7154e-04 - acc: 1.0000 - val_loss: 1.4446 - val_acc: 0.7604\n",
      "Epoch 83/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 6.5139e-04 - acc: 1.0000 - val_loss: 1.4485 - val_acc: 0.7578\n",
      "Epoch 84/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 6.3060e-04 - acc: 1.0000 - val_loss: 1.4553 - val_acc: 0.7578\n",
      "Epoch 85/100\n",
      "1150/1150 [==============================] - 0s 38us/sample - loss: 6.1338e-04 - acc: 1.0000 - val_loss: 1.4620 - val_acc: 0.7604\n",
      "Epoch 86/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 5.9576e-04 - acc: 1.0000 - val_loss: 1.4622 - val_acc: 0.7578\n",
      "Epoch 87/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 5.7678e-04 - acc: 1.0000 - val_loss: 1.4721 - val_acc: 0.7604\n",
      "Epoch 88/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 5.6321e-04 - acc: 1.0000 - val_loss: 1.4767 - val_acc: 0.7578\n",
      "Epoch 89/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 5.4367e-04 - acc: 1.0000 - val_loss: 1.4757 - val_acc: 0.7552\n",
      "Epoch 90/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 5.3065e-04 - acc: 1.0000 - val_loss: 1.4897 - val_acc: 0.7630\n",
      "Epoch 91/100\n",
      "1150/1150 [==============================] - 0s 40us/sample - loss: 5.1366e-04 - acc: 1.0000 - val_loss: 1.4848 - val_acc: 0.7552\n",
      "Epoch 92/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 4.9901e-04 - acc: 1.0000 - val_loss: 1.4941 - val_acc: 0.7578\n",
      "Epoch 93/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 4.8505e-04 - acc: 1.0000 - val_loss: 1.4975 - val_acc: 0.7604\n",
      "Epoch 94/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 4.7071e-04 - acc: 1.0000 - val_loss: 1.5030 - val_acc: 0.7604\n",
      "Epoch 95/100\n",
      "1150/1150 [==============================] - 0s 38us/sample - loss: 4.6012e-04 - acc: 1.0000 - val_loss: 1.5070 - val_acc: 0.7630\n",
      "Epoch 96/100\n",
      "1150/1150 [==============================] - 0s 44us/sample - loss: 4.4428e-04 - acc: 1.0000 - val_loss: 1.5098 - val_acc: 0.7578\n",
      "Epoch 97/100\n",
      "1150/1150 [==============================] - 0s 41us/sample - loss: 4.3530e-04 - acc: 1.0000 - val_loss: 1.5169 - val_acc: 0.7630\n",
      "Epoch 98/100\n",
      "1150/1150 [==============================] - 0s 39us/sample - loss: 4.2118e-04 - acc: 1.0000 - val_loss: 1.5182 - val_acc: 0.7578\n",
      "Epoch 99/100\n",
      "1150/1150 [==============================] - 0s 36us/sample - loss: 4.1149e-04 - acc: 1.0000 - val_loss: 1.5245 - val_acc: 0.7604\n",
      "Epoch 100/100\n",
      "1150/1150 [==============================] - 0s 42us/sample - loss: 4.0180e-04 - acc: 1.0000 - val_loss: 1.5242 - val_acc: 0.7578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1466630ed68>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3: train the model: fit epochs and batch_size\n",
    "model.fit(X_train, y_train, epochs = 100 , batch_size =120, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 1.5242 - acc: 0.7578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.524237831433614, 0.7578125]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model evaluate\n",
    "model.evaluate(X_test,y_test,verbose=2)                                                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components = 0.90)\n",
    "pca.fit(X_train)\n",
    "xTrain=pca.transform(X_train)\n",
    "xTest = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9021893405693255"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.729 (+/-0.058) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.692 (+/-0.402) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.764 (+/-0.026) for {'C': 25, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.739 (+/-0.079) for {'C': 25, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.765 (+/-0.026) for {'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.755 (+/-0.056) for {'C': 50, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.490 (+/-0.492) for {'C': 1, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 1, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.490 (+/-0.492) for {'C': 1, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 1, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.490 (+/-0.492) for {'C': 1, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 1, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 1, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 1, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.712 (+/-0.104) for {'C': 20, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 20, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.571 (+/-0.341) for {'C': 20, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 20, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.565 (+/-0.403) for {'C': 20, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 20, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.540 (+/-0.450) for {'C': 20, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 20, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.668 (+/-0.035) for {'C': 50, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.490 (+/-0.492) for {'C': 50, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.688 (+/-0.123) for {'C': 50, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 50, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.532 (+/-0.347) for {'C': 50, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 50, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.506 (+/-0.392) for {'C': 50, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.290 (+/-0.001) for {'C': 50, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.763 (+/-0.028) for {'C': 1, 'kernel': 'linear'}\n",
      "0.764 (+/-0.022) for {'C': 25, 'kernel': 'linear'}\n",
      "0.765 (+/-0.020) for {'C': 50, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "0.8816323358719051\n",
      "0.78125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       220\n",
      "           1       0.80      0.65      0.72       164\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       384\n",
      "   macro avg       0.79      0.76      0.77       384\n",
      "weighted avg       0.78      0.78      0.78       384\n",
      "\n",
      "[[194  26]\n",
      " [ 58 106]]\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.685 (+/-0.039) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.508 (+/-0.011) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.741 (+/-0.040) for {'C': 25, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.704 (+/-0.056) for {'C': 25, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.029) for {'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.721 (+/-0.040) for {'C': 50, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.005) for {'C': 1, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.502 (+/-0.005) for {'C': 1, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.502 (+/-0.005) for {'C': 1, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.551 (+/-0.016) for {'C': 20, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 20, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.506 (+/-0.013) for {'C': 20, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 20, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.503 (+/-0.013) for {'C': 20, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 20, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.501 (+/-0.014) for {'C': 20, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 20, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.618 (+/-0.024) for {'C': 50, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.502 (+/-0.005) for {'C': 50, 'degree': 2, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.517 (+/-0.016) for {'C': 50, 'degree': 3, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 50, 'degree': 3, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.505 (+/-0.018) for {'C': 50, 'degree': 4, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 50, 'degree': 4, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.501 (+/-0.015) for {'C': 50, 'degree': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.500 (+/-0.000) for {'C': 50, 'degree': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "0.739 (+/-0.016) for {'C': 1, 'kernel': 'linear'}\n",
      "0.743 (+/-0.012) for {'C': 25, 'kernel': 'linear'}\n",
      "0.743 (+/-0.014) for {'C': 50, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "0.8580212443848807\n",
      "0.78125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       220\n",
      "           1       0.80      0.65      0.72       164\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       384\n",
      "   macro avg       0.79      0.76      0.77       384\n",
      "weighted avg       0.78      0.78      0.78       384\n",
      "\n",
      "[[194  26]\n",
      " [ 58 106]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 25, 50]},\n",
    "                    {'kernel': ['poly'], 'gamma': [1e-3, 1e-4], 'degree': [2,3,4,5],'C': [1, 20, 50]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 25, 50]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    model = GridSearchCV(SVC(), tuned_parameters, cv=5, n_jobs=-1,\n",
    "                       scoring='%s_macro' % score)\n",
    "    model.fit(xTrain, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    \n",
    "#     y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    y_pred=model.predict(xTest)\n",
    "    print(model.score(xTrain,y_train))\n",
    "    print(accuracy_score(y_test, y_pred))   \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 2}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.665 (+/-0.044) for {'n_neighbors': 1}\n",
      "0.701 (+/-0.088) for {'n_neighbors': 2}\n",
      "0.669 (+/-0.037) for {'n_neighbors': 3}\n",
      "0.683 (+/-0.078) for {'n_neighbors': 4}\n",
      "0.665 (+/-0.054) for {'n_neighbors': 5}\n",
      "\n",
      "Detailed classification report:\n",
      "0.8827586206896552\n",
      "0.671875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75       220\n",
      "           1       0.70      0.40      0.51       164\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       384\n",
      "   macro avg       0.68      0.64      0.63       384\n",
      "weighted avg       0.68      0.67      0.65       384\n",
      "\n",
      "[[192  28]\n",
      " [ 98  66]]\n",
      "\n",
      "AUC_Score\n",
      "0.6375831485587583\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 3}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.661 (+/-0.044) for {'n_neighbors': 1}\n",
      "0.638 (+/-0.063) for {'n_neighbors': 2}\n",
      "0.664 (+/-0.041) for {'n_neighbors': 3}\n",
      "0.640 (+/-0.059) for {'n_neighbors': 4}\n",
      "0.657 (+/-0.055) for {'n_neighbors': 5}\n",
      "\n",
      "Detailed classification report:\n",
      "0.8344656640111185\n",
      "0.703125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75       220\n",
      "           1       0.67      0.60      0.63       164\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       384\n",
      "   macro avg       0.70      0.69      0.69       384\n",
      "weighted avg       0.70      0.70      0.70       384\n",
      "\n",
      "[[171  49]\n",
      " [ 65  99]]\n",
      "\n",
      "AUC_Score\n",
      "0.6904656319290466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "tuned_parameters = [{'n_neighbors':[1,2,3,4,5]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    model = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    model.fit(xTrain, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "   \n",
    "    y_pred = model.predict(xTest)\n",
    "    print(model.score(xTrain,y_train))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"AUC_Score\")\n",
    "    print(roc_auc_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.761 (+/-0.028) for {'penalty': 'l1'}\n",
      "0.759 (+/-0.016) for {'penalty': 'l2'}\n",
      "\n",
      "Detailed classification report:\n",
      "0.7837798694185764\n",
      "0.765625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       220\n",
      "           1       0.76      0.66      0.71       164\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       384\n",
      "   macro avg       0.76      0.75      0.76       384\n",
      "weighted avg       0.76      0.77      0.76       384\n",
      "\n",
      "\n",
      "AUC_Score\n",
      "0.7527716186252772\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'penalty': 'l1'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.744 (+/-0.014) for {'penalty': 'l1'}\n",
      "0.744 (+/-0.017) for {'penalty': 'l2'}\n",
      "\n",
      "Detailed classification report:\n",
      "0.7644162757799121\n",
      "0.765625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80       220\n",
      "           1       0.76      0.66      0.71       164\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       384\n",
      "   macro avg       0.76      0.75      0.76       384\n",
      "weighted avg       0.76      0.77      0.76       384\n",
      "\n",
      "\n",
      "AUC_Score\n",
      "0.7527716186252772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "tuned_parameters = [{'penalty':['l1', 'l2']}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    model = GridSearchCV(LogisticRegression(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    model.fit(xTrain, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "   \n",
    "    y_pred = model.predict(xTest)\n",
    "    print(model.score(xTrain,y_train))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"AUC_Score\")\n",
    "    print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c_range = [0.001, 0.01, 0.1, 1, 10, 100,1000]\n",
    "train_score_l1 = []\n",
    "train_score_l2 = []\n",
    "test_score_l1 = []\n",
    "test_score_l2 = []\n",
    "\n",
    "for c in c_range:\n",
    "    log_l1 = LogisticRegression(penalty = 'l1', C = c)\n",
    "    log_l2 = LogisticRegression(penalty = 'l2', C = c)\n",
    "    log_l1.fit(xTrain, y_train)\n",
    "    log_l2.fit(xTrain, y_train)\n",
    "    train_score_l1.append(log_l1.score(xTrain, y_train))\n",
    "    train_score_l2.append(log_l2.score(xTrain, y_train))\n",
    "    test_score_l1.append(log_l1.score(xTest, y_test))\n",
    "    test_score_l2.append(log_l2.score(xTest, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(c_range, train_score_l1, label = 'Train score, penalty = l1')\n",
    "plt.plot(c_range, test_score_l1, label = 'Test score, penalty = l1')\n",
    "plt.plot(c_range, train_score_l2, label = 'Train score, penalty = l2')\n",
    "plt.plot(c_range, test_score_l2, label = 'Test score, penalty = l2')\n",
    "plt.legend()\n",
    "plt.xlabel('Regularization parameter: C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 13}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.590 (+/-0.038) for {'max_depth': 10}\n",
      "0.591 (+/-0.055) for {'max_depth': 12}\n",
      "0.591 (+/-0.054) for {'max_depth': 13}\n",
      "0.587 (+/-0.034) for {'max_depth': 14}\n",
      "\n",
      "Detailed classification report:\n",
      "0.9904807620377528\n",
      "0.6302083333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69       220\n",
      "           1       0.57      0.53      0.55       164\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       384\n",
      "   macro avg       0.62      0.62      0.62       384\n",
      "weighted avg       0.63      0.63      0.63       384\n",
      "\n",
      "\n",
      "AUC_Score\n",
      "0.6175166297117517\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 12}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.587 (+/-0.061) for {'max_depth': 10}\n",
      "0.593 (+/-0.050) for {'max_depth': 12}\n",
      "0.587 (+/-0.059) for {'max_depth': 13}\n",
      "0.584 (+/-0.055) for {'max_depth': 14}\n",
      "\n",
      "Detailed classification report:\n",
      "0.975501327774055\n",
      "0.6380208333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69       220\n",
      "           1       0.58      0.57      0.57       164\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       384\n",
      "   macro avg       0.63      0.63      0.63       384\n",
      "weighted avg       0.64      0.64      0.64       384\n",
      "\n",
      "\n",
      "AUC_Score\n",
      "0.628991130820399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "tuned_parameters = [{'max_depth':[10,12,13,14]}] ###3 change these parameters as per need\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    model = GridSearchCV(DecisionTreeClassifier(criterion='entropy'), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    model.fit(xTrain, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "   \n",
    "    y_pred = model.predict(xTest)\n",
    "    print(model.score(xTrain,y_train))\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"AUC_Score\")\n",
    "    print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975501327774055\n",
      "0.6380208333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69       220\n",
      "           1       0.58      0.57      0.57       164\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       384\n",
      "   macro avg       0.63      0.63      0.63       384\n",
      "weighted avg       0.64      0.64      0.64       384\n",
      "\n",
      "\n",
      "AUC_Score\n",
      "0.628991130820399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "classifier.fit(xTrain, y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "y_pred = model.predict(xTest)\n",
    "print(model.score(xTrain,y_train))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"AUC_Score\")\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.784\n",
      "Accuracy on test set: 0.768\n",
      "Detailed classification report:\n",
      "\n",
      "0.975501327774055\n",
      "0.6380208333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69       220\n",
      "           1       0.58      0.57      0.57       164\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       384\n",
      "   macro avg       0.63      0.63      0.63       384\n",
      "weighted avg       0.64      0.64      0.64       384\n",
      "\n",
      "\n",
      "AUC_Score\n",
      "0.628991130820399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC().fit(xTrain, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(linear_svm.score(xTrain, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(linear_svm.score(xTest, y_test)))\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "y_pred = model.predict(xTest)\n",
    "print(model.score(xTrain,y_train))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print(\"AUC_Score\")\n",
    "print(roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "c_range = [0.001, 0.01, 0.1, 1, 10, 100,1000]\n",
    "train_score_linearsvc_l1 = []\n",
    "train_score_linearsvc_l2 = []\n",
    "test_score_linearsvc_l1 = []\n",
    "test_score_linearsvc_l2 = []\n",
    "\n",
    "for c in c_range:\n",
    "    #log_l1 = LinearSVC(penalty = 'l1', C = c)\n",
    "    log_l2 = LinearSVC(penalty = 'l2', C = c)\n",
    "    #log_l1.fit(xTrain, yTrain)\n",
    "    log_l2.fit(xTrain, y_train)\n",
    "   # train_score_linearsvc_l1.append(log_l1.score(xTrain, yTrain))\n",
    "    train_score_linearsvc_l2.append(log_l2.score(xTrain, y_train))\n",
    "    #test_score_linearsvc_l1.append(log_l1.score(xTest, yTest))\n",
    "    test_score_linearsvc_l2.append(log_l2.score(xTest, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plt.plot(c_range, train_score_linearsvc_l1, label = 'Train score, penalty = l1')\n",
    "# plt.plot(c_range, test_score_linearsvc_l1, label = 'Test score, penalty = l1')\n",
    "plt.plot(c_range, train_score_linearsvc_l2, label = 'Train score, penalty = l2')\n",
    "plt.plot(c_range, test_score_linearsvc_l2, label = 'Test score, penalty = l2')\n",
    "plt.legend()\n",
    "plt.xlabel('Regularization parameter: C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After applying PCA, the above models doesn't give better results as evident from the respective accuracy score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM                   \n",
    "### Accuracy on test set for linear kernel with C= 50:  0.9114583333333334\n",
    "\n",
    "## KNN\n",
    "### Accuracy on test set for 3 nearest neighbours:0.7161458333333334, AUC_Score: 0.4834821428571428\n",
    "\n",
    "## Logistic Regression\n",
    "### Accuracy on test set: 0.8385416666666666, AUC_Score: 0.5077050997782706\n",
    "\n",
    "## Linear SVC\n",
    "###  Accuracy on test set: 0.576, MSE: 0.4244791666666667, AUC_Score: 0.5077050997782706\n",
    "\n",
    "\n",
    "## Random Forest\n",
    "### Accuracy on test set: 0.9192708333333334; AUC_Score: 0.4834821428571428\n",
    "\n",
    "## Decision Tree\n",
    "### Accuracy on test set for maximum depth = 10: 0.9192708333333334,  AUC_Score: 0.4834821428571428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
